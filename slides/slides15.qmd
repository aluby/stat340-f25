---
title: Regression
subtitle: Day 15
title-slide-attributes:
  data-background-color: "#e2583eff"
  data-slide-number: none
format: 
  revealjs:
    incremental: false
    scrollable: false
auto-stretch: true
editor_options: 
  chunk_output_type: console
editor: 
  markdown: 
    wrap: 72
execute: 
  warning: false
  message: false
---

```{r}
#| echo: false
#| warning: false
#| message: false

library(countdown)
library(tidyverse)
library(bayesrules)
library(janitor)
library(patchwork)
library(rstan)
library(bayesplot)

theme_set(theme_minimal(base_size = 16, base_family = "Atkinson Hyperlegible"))
```

## Plan for today

- Review some key ideas from regression
- Introduce Bayesian simple linear regression

## Background

Let $Y$ be a response variable and $X = (X_1, X_2, ..., X_p)$ be a set of predictors. Then the normal regression model of $Y$ vs $X$ is: 

$$Y = \beta_0 + \beta_1 X_1 + \beta_2 X2 + ... + \beta_p X_p + \varepsilon$$

where

- $E(Y|X) = \beta_0 + \beta_1 X_1 + \beta_2 X2 + ... + \beta_p X_p$  is the expected or typical $Y$ outcome at the given set of predictor values
- $\varepsilon$ = residual error, i.e. how much the observed outcome of  $Y$ deviates from the expected outcome. We assume that these errors are Normally distributed around 0 with some standard deviation  $\sigma$

## Example: bikeshare rides against feels like temperature

```{r}
ggplot(bikes, aes(x = temp_feel, y = rides)) + 
  geom_point() + 
  geom_smooth(method = "lm")
```

## What is the estimated model equation?

```{r}
model_1 <- lm(rides ~ temp_feel, data = bikes)
coef(summary(model_1))
```


How do we interpret 81.9? 

(a) For every 1 degree increase in temperature, we expect around 81.9 more riders.
(b) For every extra rider, we expect temperature to increase by around 81.9 degrees.
(c) We expect around 81.9 riders on 0-degree days.

## Centered intercept

```{r}
bikes %>% 
    summarize(mean(temp_feel))
```

## Example: bikeshare rides against weekend

```{r}
ggplot(bikes, aes(x = weekend, y = rides)) + 
   geom_boxplot()
```

##  What is the estimated model equation?

```{r}
model_2 <- lm(rides ~ weekend, data = bikes)
coef(summary(model_2))
```

How can we interpret 3712.1?    

(a) We expect 3712 more riders on weekdays than weekends.
(b) We expect 3712 more riders on weekends than weekdays.
(c) We expect 3712 riders on weekends
(d) We expect 3712 riders on weekdays.

## 

How can we interpret -815.3?

(a) For each additional weekend, we expect 815 fewer riders.
(a) We expect 815 fewer riders on weekdays than weekends.
(a) We expect 815 fewer riders on weekends than weekdays.
(a) We expect -815 riders on weekends.
(a) We expect -815 riders on weekdays.

Predict the number of riders there will be on Saturday. 


## Combining the two

```{r}
ggplot(bikes, aes(x = temp_feel, y = rides, color = weekend)) + 
  geom_point() +
  geom_smooth(method = "lm")
```

## 

```{r}
model_3 <- lm(rides ~ temp_feel + weekend, data = bikes)
coef(summary(model_3))
```

## 

Normal model: 

$$Y_i | \mu, \sigma \sim N(\mu, \sigma^2)$$

Normal regression model: 

$$Y_i | \beta_0, \beta_1, \sigma \sim N(\mu_i, \sigma^2), \text{ with } \mu_i = \beta_0 + \beta_1 X_i$$

Make it Bayesian: 

$$\beta_0 \sim N(m_0, s_0^2)$$

$$\beta_1 \sim N(m_1, s_1^2)$$

$$\sigma \sim \text{Exp}(l)$$

## Model building: one step at a time

Let $Y$ be a response variable and let $X$ be a predictor or set of predictors. We build a model of $Y$ by $X$ through the following general principles: 

- Is $Y$ discrete or continuous? What is an approrpiate data model? (e.g. Normal, Poisson, Binomial, etc)
- Rewrite the mean of $Y$ as a function of predictors $X$
- Identify all unknown parameters (eg $\beta_0, \beta_1, \sigma$)
- What values might each of these parameters take? What prior models represent those beliefs faithfully?

## Prior + Likelihood = Posterior

$$f(\beta_0, \beta_1, \sigma) = f(\beta_0) f(\beta_1) f(\sigma)$$
$$L(\beta_0, \beta_1, \sigma | \vec{y}) = \prod f(y_i | \beta_0, \beta_1, \sigma)$$

$$f(\beta_0, \beta_1, \sigma | \vec{y}) = $$

## Simulate with {rstan}

```{r}
# STEP 1: DEFINE the model
stan_bike_model <- "
  data {
    int<lower = 0> n;
    vector[n] Y;
    vector[n] X;
  }
  parameters {
    real beta0;
    real beta1;
    real<lower = 0> sigma;
  }
  model {
    Y ~ normal(beta0 + beta1 * X, sigma);
    beta0 ~ normal(-2000, 1000);
    beta1 ~ normal(100, 40);
    sigma ~ exponential(1);
  }
"
```

## Simulate with {rstan}

```{r}
#| eval: false
# STEP 2: SIMULATE the posterior
stan_bike_sim <- 
  stan(model_code = stan_bike_model, 
       data = list(n = nrow(bikes), Y = bikes$rides, X = bikes$temp_feel), 
       chains = 4, iter = 5000*2, seed = 84735)

save(stan_bike_sim, file = "slides/15-bike-fit.rda")
```

```{r}
#| echo: false

load("15-bike-fit.rda")
```

```{r}
library(broom.mixed)
tidy(stan_bike_sim, conf.int = TRUE, conf.level = .8)
```

## Simulate with {rstanarm}

```{r}
library(rstanarm)

bike_model <- stan_glm(rides ~ temp_feel, data = bikes,
                       family = gaussian,
                       prior_intercept = normal(5000, 1000),
                       prior = normal(100, 40), 
                       prior_aux = exponential(1),
                       chains = 4, iter = 5000*2, seed = 84735, refresh = 0)

tidy(bike_model, conf.int = TRUE, conf.level = .8)
```

## Simulate with {rstanarm} {.smaller}

```{r}
bike_model
```

## `add_fitted_draws`

```{r}
#| warning: false
#| message: false
library(tidybayes)
# 50 simulated model lines
bikes %>%
  add_fitted_draws(bike_model, n = 50) %>%
  ggplot(aes(x = temp_feel, y = rides)) +
    geom_line(aes(y = .value, group = .draw), alpha = 0.15) + 
    geom_point(data = bikes, size = 0.05)
```
