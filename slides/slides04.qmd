---
title: Beta-Binomial Model
subtitle: Day 04
title-slide-attributes:
  data-background-color: "#e2583eff"
  data-slide-number: none
format: 
  revealjs:
    incremental: false
auto-stretch: false
editor_options: 
  chunk_output_type: console
editor: 
  markdown: 
    wrap: 72
execute: 
  warning: false
  message: false
---

```{r}
#| echo: false
#| warning: false
#| message: false

library(countdown)
library(tidyverse)
library(bayesrules)
library(janitor)
library(patchwork)

theme_set(theme_minimal(base_size = 14, base_family = "Atkinson Hyperlegible"))
```

## Back to Graduate School Applications

Last week we were trying to understand $\pi$ the acceptance rate of a graduate program in a specific department. We assumed a somewhat silly prior, and restricted $\pi$ to be 0.2, 0.4, or 0.8.

This time we will let $\pi \in [0,1]$. 

##

**Continuous probability models**    
 
Let $\pi$ be a continuous random variable with pdf $f(\pi)$.
Then $f(\pi)$ has the following properties:    

- $\int_\pi f(\pi)d\pi = 1$, ie. the area under $f(\pi)$ is 1
- $f(\pi) \ge 0$
- $P(a < \pi < b) = \int_a^b f(\pi) d\pi$ when $a \le b$

Interpreting $f(\pi)$:

$f(\pi)$ can be used to _compare_ the plausibility of two different values of $\pi$.

## 

::: task

For each of the student's prior ideas for $\pi$ sketch the pdf of the prior. Your plot will not be exact since no exact values are given.  
:::


::::: columns
::: {.column width="50%"}
Morteza thinks that it is extremely difficult to get into this program.

```{r}
#| echo: false


tibble(
  pi = seq(0, 1, by = .01)
) |>
  ggplot(aes(x = pi)) +
  theme_bw(base_family = "Atkinson Hyperlegible")
```

:::

::: {.column width="50%"}
Erin does not have any strong opinions whether it is difficult or easy to get into this program. 

```{r}
#| echo: false


tibble(
  pi = seq(0, 1, by = .01)
) |>
  ggplot(aes(x = pi)) +
  theme_bw(base_family = "Atkinson Hyperlegible")
```
:::
:::::





## 

::: task

For each of the student's prior ideas for $\pi$ sketch the pdf of the prior. Your plot will not be exact since no exact values are given.  
:::


::::: columns
::: {.column width="50%"}
Xuan thinks that it is easy to get into this program.

```{r}
#| echo: false


tibble(
  pi = seq(0, 1, by = .01)
) |>
  ggplot(aes(x = pi)) +
  theme_bw(base_family = "Atkinson Hyperlegible")
```

:::

::: {.column width="50%"}
BeyoncÃ© thinks that it is extremely easy to get into this program.


```{r}
#| echo: false


tibble(
  pi = seq(0, 1, by = .01)
) |>
  ggplot(aes(x = pi)) +
  theme_bw(base_family = "Atkinson Hyperlegible")
```
:::
:::::

## Beta Prior model

Let $\pi$ be a random variable which can take any value between 0 and 1, ie. $\pi \in [0,1]$.
Then the variability in $\pi$ might be well modeled by a Beta model with __shape parameters__ $\alpha > 0$ and $\beta > 0$: 

$$\pi \sim \text{Beta}(\alpha, \beta)$$

##

The Beta model is specified by continuous pdf
\begin{equation}
f(\pi) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \pi^{\alpha-1} (1-\pi)^{\beta-1} \;\; \text{ for } \pi \in [0,1] 
\end{equation}

 where $\Gamma(z) = \int_0^\infty y^{z-1}e^{-y}dy$ and $\Gamma(z + 1) = z \Gamma(z)$.  
 
 Fun fact: when $z$ is a positive integer, then $\Gamma(z)$ simplifies to $\Gamma(z) = (z-1)!$.   

## Beta Prior model

::::: columns
::: {.column width="50%"}

```{r}
#| echo: false
#| warning: false
#| fig-align: center

plot_beta(3, 8) +
  geom_segment(aes(x = 0.50, y = 0, xend = 0.50, yend = dbeta(0.50, 3,8)), color = "orange2") +
    annotate("text", label = "(0.5, ?)", x = 0.6, y = 0.9, size = 8, colour = "orange2")

  
```

:::




::: {.column width="50%"}

$\pi \sim \text{Beta}(3, 8)$

$f(\pi) = \frac{\Gamma(\alpha + \beta)}{\Gamma(\alpha)\Gamma(\beta)} \pi^{\alpha-1} (1-\pi)^{\beta-1}$ 


$f(0.5) =$


:::
:::::

## Beta Prior model

$\pi \sim \text{Beta}(3, 8)$

::::: columns
::: {.column width="50%"}

```{r}
#| echo: false
#| warning: false
#| fig-align: center
plot_beta(3, 8) +
  geom_segment(aes(x = 0.50, y = 0, xend = 0.50, yend = dbeta(0.50, 3,8)), color = "orange2") +
    annotate("text", label = "(0.5, ?)", x = 0.6, y = 0.9, size = 8, colour = "orange2")

  
```

:::




::: {.column width="50%"}

```{r}
dbeta(x = 0.5, 
      shape1 = 3, 
      shape2 = 8)
```



:::

:::::

## Plotting Beta prior

```{r}
#| echo: false
#| fig-align: center
#| message: false
# Set up beta data

alpha <- c(1,1,3,1,5,20,7,2,5)
beta  <- c(5,2,7,1,5,20,3,1,1)
betas <- data.frame(setting = factor(rep(1:9, 
                                         each = 500)), 
                    x = rep(seq(0, 1, 
                                length = 500), 9),
                    alpha = rep(alpha, each = 500),
                    beta = rep(beta, each = 500))

betas <- betas %>% 
  mutate(y = dbeta(x, shape1 = alpha, shape2 = beta))

levels(betas$setting) <-
  paste0("Beta(",alpha,",",beta,")")

trend_data <- data.frame(alpha, beta,
                         means = (alpha / (alpha +
                                             beta)),
                         modes = 
                           ((alpha - 1) / 
                              (alpha + beta - 2))) %>% 
  mutate(Parameter = 
           paste0("Beta(",alpha,",",beta,")")) %>% 
  mutate(setting = Parameter) %>% 
  mutate(means_d = dbeta(means, alpha, beta), 
         modes_d = dbeta(modes, alpha, beta))

trend_data$setting <- factor(trend_data$setting, 
                             levels = c("Beta(1,5)",
                                        "Beta(1,2)",
                                        "Beta(3,7)",
                                        "Beta(1,1)",
                                        "Beta(5,5)",
                                        "Beta(20,20)",
                                        "Beta(7,3)",
                                        "Beta(2,1)",
                                        "Beta(5,1)"))
  
ggplot(betas, aes(x = x, y = y)) + 
  lims(x = c(0,1), y = c(0,5.5)) + 
  geom_line() + 
  facet_wrap(~ setting) + 
  labs(x = expression(pi), y =
         expression(paste("f(",pi,")"))) + 
  scale_x_continuous(breaks = c(0,0.25,0.5,0.75,1),
                     labels =
                       c("0","0.25","0.50","0.75","1")) 

```


## Plotting Beta Prior with `bayesrules` package


```{r}
#| fig-align: center
plot_beta(alpha = 5, beta = 7) 
```

## Beta summaries

$$E(\pi) = \frac{\alpha}{\alpha + \beta}$$

$$\text{Mode}(\pi) = \frac{\alpha - 1}{\alpha + \beta - 2}$$  

$$\text{Var}(\pi) = \frac{\alpha \beta}{(\alpha + \beta)^2(\alpha + \beta + 1)}$$

## Beta summaries with `bayesrules` package

Use the `summarize_beta()` function in the `bayesrules` package to find the mean, mode, and variance of various Beta distributions. Example:

```{r}
summarize_beta(alpha = 5, beta = 7)
```

## Posterior for the Beta-Binomial model

## Posterior for the Beta-Binomial model

## Conjugate prior

We say that $f(\pi)$ is a conjugate prior for $L(\pi|y)$ if the posterior, $f(\pi|y) \propto f(\pi)L(\pi|y)$, is from the same model family as the prior.  

Thus, the Beta distribution is a conjugate prior for the Binomial likelihood model since the posterior also follows a Beta distribution.


## Admission Example

::::: columns
Original discrete prior:

::: {.column width="50%"}

| $\pi$    | 0.2 | 0.4 | 0.8  |
|----------|-----|-----|------|
| $f(\pi)$ |.7   | .2  |   .1 |

:::

::: {.column width="50%" .fragment}
Beta approximation:

```{r}
plot_beta(3, 7, mean = TRUE, mode = TRUE) 
```
:::

:::::

## Data + Posterior

3/5 students were admitted 

$$ \pi \sim \text{Beta}(3, 7)$$
$$ \pi | Y \sim \text{Beta}(3 + y, 7 + n -y)$$
$$ \pi | Y \sim \text{Beta}(6, 9)$$

## Posterior summary

```{r}
#| warning: false
#| message: false

summarize_beta(6,9)
plot_beta(6, 9, mean = TRUE, mode = TRUE) 
```

## Balancing act

```{r}
plot_beta_binomial(alpha = 3, beta = 7,
                   y = 3, n = 5)
```

## More data, more certainty

What if 30/50 applicants get in?

```{r}
plot_beta_binomial(alpha = 3, beta = 7,
                   y = 30, n = 50)
```

## More more data, more more certainty

What if 300/500 applicants get in?

```{r}
plot_beta_binomial(alpha = 3, beta = 7,
                   y = 300, n = 500)
```

# Simulating the Beta-Binomial model

## Data Context

Let $\pi$ represent the proportion of students who are admitted to the program. 

$Y | \pi \sim \text{Binom}(n, \pi)$

## Prior

```{r}
plot_beta(3, 7)
```


## Data and the Posterior

30/50 students are admitted

```{r}
summarize_beta_binomial(3, 7, y = 30, n = 50)
```

##

```{r}
plot_beta_binomial(3, 7, y = 30, n = 50)
```

##

```{r}
set.seed(84735)
admission_sim <- data.frame(pi = rbeta(10000, 3, 7)) 
head(admission_sim)

admission_sim <- admission_sim |>
  mutate(y = rbinom(10000, size = 50, prob = pi))
```

##

```{r echo=FALSE}
head(admission_sim, n = 10) |> 
  gt::gt()
```

## Simulation outcomes

```{r}
#| echo: false
admission_sim |>
  ggplot(aes(x = pi, y = y)) + 
  geom_point()
```

## Simulation outcomes **that match the data**

```{r}
#| echo: false
admission_sim |>
  ggplot(aes(x = pi, y = y, col = y == 30)) + 
  geom_point() + 
  scale_color_manual(values = c("black", "darkorange"), guide = FALSE) 
```


## Simulation outcomes **that match the data**

```{r}
admission_posterior <- admission_sim |> 
  filter(y == 30)
```

```{r}
nrow(admission_posterior)
```

$f(\pi|y =30)$

## Simulated Posterior

```{r}
ggplot(admission_posterior, aes(x = pi)) + 
  geom_histogram(color = "white", binwidth = 0.025) 
```


## Simulated posterior density estimate

```{r}
ggplot(admission_posterior, aes(x = pi)) + 
  geom_density() +
  xlim(0,1)
```

##

```{r echo=FALSE}
p1 <- plot_beta_binomial(3, 7, y = 30, n = 50, 
                   prior = FALSE, likelihood=FALSE) +
  theme(legend.position = "none") +
  labs(title = "Beta(33, 27)")

p2 <- ggplot(admission_posterior, aes(x = pi)) + 
  geom_density() +
  xlim(0,1) +
  labs(title = "Posterior Simulation")

p1 / p2
```


