---
title: Normal-Normal model
subtitle: Day 07
title-slide-attributes:
  data-background-color: "#e2583eff"
  data-slide-number: none
format: 
  revealjs:
    incremental: false
    scrollable: false
auto-stretch: true
editor_options: 
  chunk_output_type: console
editor: 
  markdown: 
    wrap: 72
execute: 
  warning: false
  message: false
---



```{r}
#| echo: false
#| warning: false
#| message: false

library(countdown)
library(tidyverse)
library(bayesrules)
library(janitor)
library(patchwork)

theme_set(theme_minimal(base_size = 16, base_family = "Atkinson Hyperlegible"))
```

## Recap

- Start with a reasonable **likelihood** for the data
- A **conjugate prior** for a given likelihood is a prior model that results in a posterior with the same shape, but different parameters
- The beta distribution is a conjugate prior for the binomial likelihood
- The gamma distribution is a conjugate prior for the poisson likelihood

## 

### Beta-Binomial Bayesian Model

$$\pi \sim \text{Beta}(\alpha, \beta)$$
$$ Y | \pi  \sim \text{Binomial}(n, \pi)$$
$$ \pi |Y \sim \text{Beta}(\alpha + y, \beta + n - y)$$

### Gamma-Poisson Bayesian Model

$$\lambda \sim \text{Gamma}(s, r)$$
$$ Y_i | \lambda \sim \text{Poisson}(\lambda)$$

$$\lambda | Y_1, Y_2, ..., Y_n \sim \text{Gamma}(s + \sum Y_i, r + n)$$

## Data



## Normal Model

Let $Y$ be a random variable which can take any value $Y \in (-\infty,\infty)$ and is unimodal and symmetric.  Then $Y$ might be well represented by a Normal model with __mean parameter__ $\mu \in (-\infty, \infty)$ and __standard deviation parameter__ $\sigma > 0$: 

$$Y \sim N(\mu, \sigma^2)$$

The Normal model is specified by continuous pdf

\begin{equation}
f(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\bigg[{-\frac{(y-\mu)^2}{2\sigma^2}}\bigg] \;\; \text{ for } y \in (-\infty,\infty)
\end{equation}

## 

$E(Y) = \mu, \text{Mode}(Y) = \mu, \text{Var}(Y) = \sigma^2$

```{r echo=FALSE, normal-tuning, fig.width = 4.5, message=FALSE, fig.width=12}

# Set up gamma data
mu <- c(2,2,4)
sigma  <- c(.5,1,2)
sigma.sq<-sigma^2
normals <- data.frame(setting = factor(rep(1:3, each = 500)), 
                    x = rep(seq(-2, 10, length = 500), 3),
                    mu = rep(mu, each = 500), 
                    sigma = rep(sigma, each = 500))
normals <- normals %>% 
    mutate(y = dnorm(x, mean = mu, sd = sigma))
levels(normals$setting) <- paste0("N(",mu,",",sigma.sq,")")
g <- ggplot(normals, aes(x = x, y = y)) + 
  geom_line() + 
  facet_wrap(~ setting) + 
  labs(x = "y", y = "f(y)") + 
  scale_y_continuous(breaks = c(0,2,4,6,8,10)) + 
  lims(y = c(0,0.8)) 
  
g 
``` 

## Normal Likelihood

## Normal-Normal Bayesian Model 

Let $\mu \in (-\infty,\infty)$ be an unknown _mean_ parameter and $(Y_1,Y_2,\ldots,Y_n)$ be an independent $N(\mu,\sigma^2)$ sample where $\sigma$ is assumed to be _known_.
The Normal-Normal Bayesian model complements the Normal structure of the data with a Normal prior on $\mu$:

$$\mu \sim N(\theta, \tau^2)$$ 
$$Y_i | \mu  \stackrel{iid}{\sim} N(\mu, \sigma^2)$$
$$\mu|\vec{y} \; \sim \;  N\bigg(\frac{\theta\sigma^2/n + \bar{y}\tau^2}{\tau^2+\sigma^2/n}, \; \frac{\tau^2\sigma^2/n}{\tau^2+\sigma^2/n}\bigg)$$


::: aside
You'll show this on homework this week! 
:::

## Posterior Mean as weighted average 


## Example


## Multiparameter model

