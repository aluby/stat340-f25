---
title: Normal-Normal model
subtitle: Day 07
title-slide-attributes:
  data-background-color: "#e2583eff"
  data-slide-number: none
format: 
  revealjs:
    incremental: false
    scrollable: false
auto-stretch: true
editor_options: 
  chunk_output_type: console
editor: 
  markdown: 
    wrap: 72
execute: 
  warning: false
  message: false
---



```{r}
#| echo: false
#| warning: false
#| message: false

library(countdown)
library(tidyverse)
library(bayesrules)
library(janitor)
library(patchwork)

theme_set(theme_minimal(base_size = 16, base_family = "Atkinson Hyperlegible"))
```

```{r}
#| echo: false
Howell1 <- readr::read_delim("https://raw.githubusercontent.com/rmcelreath/rethinking/master/data/Howell1.csv", delim = ";")
adults <- filter(Howell1, age >= 18)
```

## Recap

- Start with a reasonable **likelihood** for the data
- A **conjugate prior** for a given likelihood is a prior model that results in a posterior with the same shape, but different parameters
- The beta distribution is a conjugate prior for the binomial likelihood
- The gamma distribution is a conjugate prior for the poisson likelihood

## 

### Beta-Binomial Bayesian Model

$$\pi \sim \text{Beta}(\alpha, \beta)$$
$$ Y | \pi  \sim \text{Binomial}(n, \pi)$$
$$ \pi |Y \sim \text{Beta}(\alpha + y, \beta + n - y)$$

### Gamma-Poisson Bayesian Model

$$\lambda \sim \text{Gamma}(s, r)$$
$$ Y_i | \lambda \sim \text{Poisson}(\lambda)$$

$$\lambda | Y_1, Y_2, ..., Y_n \sim \text{Gamma}(s + \sum Y_i, r + n)$$

## Data

Data on heights (in cm) of 352 adults

```{r echo=FALSE, message=FALSE, fig.height = 3.5, fig.width = 5, fig.align='center'}
ggplot(adults) +
  geom_histogram(aes(x = height), bins = 20, color="white") 
```

## Normal Model

Let $Y$ be a random variable which can take any value $Y \in (-\infty,\infty)$ and is unimodal and symmetric.  Then $Y$ might be well represented by a Normal model with __mean parameter__ $\mu \in (-\infty, \infty)$ and __standard deviation parameter__ $\sigma > 0$: 

$$Y \sim N(\mu, \sigma^2)$$

The Normal model is specified by continuous pdf

\begin{equation}
f(y) = \frac{1}{\sqrt{2\pi\sigma^2}} \exp\bigg[{-\frac{(y-\mu)^2}{2\sigma^2}}\bigg] \;\; \text{ for } y \in (-\infty,\infty)
\end{equation}

## 

$E(Y) = \mu, \text{Mode}(Y) = \mu, \text{Var}(Y) = \sigma^2$

```{r echo=FALSE, normal-tuning, fig.width = 4.5, message=FALSE, fig.width=12}

# Set up gamma data
mu <- c(2,2,4)
sigma  <- c(.5,1,2)
sigma.sq<-sigma^2
normals <- data.frame(setting = factor(rep(1:3, each = 500)), 
                    x = rep(seq(-2, 10, length = 500), 3),
                    mu = rep(mu, each = 500), 
                    sigma = rep(sigma, each = 500))
normals <- normals %>% 
    mutate(y = dnorm(x, mean = mu, sd = sigma))
levels(normals$setting) <- paste0("N(",mu,",",sigma.sq,")")
g <- ggplot(normals, aes(x = x, y = y)) + 
  geom_line() + 
  facet_wrap(~ setting) + 
  labs(x = "y", y = "f(y)") + 
  scale_y_continuous(breaks = c(0,2,4,6,8,10)) + 
  lims(y = c(0,0.8)) 
  
g 
``` 

## Terminology 

- Normal: "usual" or "customary" 
  - Statisticians historically called it "normal" because it was the "usual" distribution for, e.g., the CLT
- Gaussian: name the distribution for the person who developed it
  - Also not quite right, since DeMoivre first proved the CLT 
- Both terms describe the same mathematical function

## Normal Likelihood

## Normal-Normal Bayesian Model 

Let $\mu $ be an unknown _mean_ parameter and $(Y_1,Y_2,\ldots,Y_n)$ be an independent $N(\mu,\sigma^2)$ sample where $\sigma$ is assumed to be _known_.

$$\mu \sim N(\theta, \tau^2)$$ 
$$Y_i | \mu  \stackrel{iid}{\sim} N(\mu, \sigma^2)$$
$$\mu|\vec{y} \; \sim \;  N\bigg(\frac{\theta\sigma^2/n + \bar{y}\tau^2}{\tau^2+\sigma^2/n}, \; \frac{\tau^2\sigma^2/n}{\tau^2+\sigma^2/n}\bigg)$$


::: aside
You'll show this on homework this week! 
:::

## Posterior Mean as weighted average 

## Example

::::: columns
::: {.column width="70%"}

- Partial census data for the Dobe area !Kung San, a foraging population

- Compiled from Nancy Howell's interviews

```{r}
#| echo: false
adults
```

:::

::: {.column width="30%"}
![](img/howell-cover.jpg)
:::
:::::

## Example

Let's say we're interested in analyzing the average height of an adult

```{r echo=FALSE, message=FALSE, fig.height = 3.5, fig.width = 5, fig.align='center'}
ggplot(adults) +
  geom_histogram(aes(x = height), bins = 20, color="white") 
```

::: aside
Anthropologists would be interested in more complex relationships, but we have to start somewhere.
:::

## Example

```{r}
plot_normal(170, 20)
```

## Example

```{r}
adults |>
  summarize(
    mean = mean(height),
    sd = sd(height),
    n = n()
  )
```

## Example

```{r message=FALSE, fig.align='center'}
plot_normal_normal(mean = 170, 
                        sd = 20, 
                        sigma = sd(adults$height), 
                        y_bar = mean(adults$height),
                        n = length(adults$height))
```

## Example

```{r}
summarize_normal_normal(mean = 170, 
                        sd = 20, 
                        sigma = sd(adults$height), 
                        y_bar = mean(adults$height),
                        n = length(adults$height))
```

## What if we only had a sample of 35?

```{r echo=FALSE, message=FALSE, fig.align='center'}
plot_normal_normal(mean = 170, 
                        sd = 20, 
                        sigma = sd(adults$height), 
                        y_bar = mean(adults$height),
                        n = 35)
```

## What if we only had a sample of 3?

```{r echo=FALSE, message=FALSE, fig.align='center'}
plot_normal_normal(mean = 170, 
                        sd = 20, 
                        sigma = sd(adults$height), 
                        y_bar = mean(adults$height),
                        n = 3)
```

## Multiparameter model

